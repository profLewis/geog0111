{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Reconciling projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#3.6-Reconciling-projections\" data-toc-modified-id=\"3.6-Reconciling-projections-1\">3.6 Reconciling projections</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.6.A-Introduction\" data-toc-modified-id=\"3.6.A-Introduction-1.1\">3.6.A Introduction</a></span></li><li><span><a href=\"#3.6.A.1-Requirements\" data-toc-modified-id=\"3.6.A.1-Requirements-1.2\">3.6.A.1 Requirements</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.6.A.2-Get-the-MODIS-LAI-datasets-for-2016/2017-for-W.-Europe\" data-toc-modified-id=\"3.6.A.2-Get-the-MODIS-LAI-datasets-for-2016/2017-for-W.-Europe-1.2.1\">3.6.A.2 Get the MODIS LAI datasets for 2016/2017 for W. Europe</a></span></li><li><span><a href=\"#3.6.A.3-Get-the-shapefile-for-country-borders\" data-toc-modified-id=\"3.6.A.3-Get-the-shapefile-for-country-borders-1.2.2\">3.6.A.3 Get the shapefile for country borders</a></span></li><li><span><a href=\"#3.6.A.4-Read-the-LAI-dataset-for-a-given-country-and-year\" data-toc-modified-id=\"3.6.A.4-Read-the-LAI-dataset-for-a-given-country-and-year-1.2.3\">3.6.A.4 Read the LAI dataset for a given country and year</a></span></li><li><span><a href=\"#3.6.A.5-register-with-ECMWF-and-install-the-API\" data-toc-modified-id=\"3.6.A.5-register-with-ECMWF-and-install-the-API-1.2.4\">3.6.A.5 register with ECMWF and install the API</a></span></li><li><span><a href=\"#3.6.2.4-Get-the-2t-dataset-from-ECMWF-for-Europe\" data-toc-modified-id=\"3.6.2.4-Get-the-2t-dataset-from-ECMWF-for-Europe-1.2.5\">3.6.2.4 Get the 2t dataset from ECMWF for Europe</a></span></li><li><span><a href=\"#3.6.2.5-Generate-dataset-wkt-and-correct-ECMWF-file\" data-toc-modified-id=\"3.6.2.5-Generate-dataset-wkt-and-correct-ECMWF-file-1.2.6\">3.6.2.5 Generate dataset wkt and correct ECMWF file</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.A Introduction\n",
    "\n",
    "This section of notes is optional to the course, and the tutor may decide *not* to go through this in class. That said, the information and obexamples contained here can be very useful for accessing and processing certain types of geospatial data.\n",
    "\n",
    "In particular, we deal with obtaining climate data records from [ECMWF](http://apps.ecmwf.int/datasets/data/era40-daily/levtype=sfc) that we will later use for model fitting. These data come in a [netcdf](https://confluence.ecmwf.int/display/CKB/What+are+NetCDF+files+and+how+can+I+read+them) format (commonly used for climate data) with a grid in latitude/longitude. To 'overlay' these data with another dataset (e.g. the MODIS LAI product that we have been using) in a different (equal area) projection, we use the `gdal` function\n",
    "\n",
    "    gdal.ReprojectImage(src, dst, src_proj, dst_proj, interp)\n",
    "       \n",
    "where:\n",
    "\n",
    "    src      : a source dataset that we want to process \n",
    "    dst      : a blank destination dataset that we set up with the \n",
    "               required (output) data type, shape, and geotransform and projection\n",
    "    src_proj : the source dataset projection wkt \n",
    "    dst_proj : the destination projection wkt \n",
    "    interp   : the required interpolation method, e.g. gdalconst.GRA_Bilinear\n",
    "    \n",
    "where wkt stands for [well known text](https://en.wikipedia.org/wiki/Well-known_text) and is a projection format string.\n",
    "\n",
    "Other codes we use are ones we have developed earlier.\n",
    "\n",
    "In these notes, we will learn:\n",
    "\n",
    "    * how to access an ECMWF daily climate dataset (from ERA interim)\n",
    "    * how to reproject the dataset to match another spatial dataset (MODIS LAI)\n",
    "    \n",
    "We will then save some datasets that we will use later in the notes. For this reason, it's possile to skip this section, and return to it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.A.1 Requirements\n",
    "\n",
    "We will need to:\n",
    "\n",
    "* make sure we have the MODIS LAI dataset locally\n",
    "* read them in for a given country.\n",
    "* register with ecmwf, install ecmwfapi\n",
    "* get the temperature datasset from ECMWF for 2006 and 2017 for Europe\n",
    "* get the country borders shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required general imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdal\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "year = 2017\n",
    "country_code = 'GM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run all of the below with the script, unless you want to change any of the conditions (e.g. year or country):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europe_data_2016_2017.nc exists\n",
      "GEOGCS[\"Coordinate System imported from GRIB file\",DATUM[\"unknown\",SPHEROID[\"Sphere\",6371200,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433]]\n",
      "PROJCS[\"MODIS Sinusoidal\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"false_easting\",0.0],PARAMETER[\"false_northing\",0.0],PARAMETER[\"central_meridian\",0.0],PARAMETER[\"semi_major\",6371007.181],PARAMETER[\"semi_minor\",6371007.181],UNIT[\"m\",1.0],AUTHORITY[\"SR-ORG\",\"6974\"]]\n"
     ]
    }
   ],
   "source": [
    "%run geog0111/Chapter3_6A_prerequisites.py UK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.A.2 Get the MODIS LAI datasets for 2016/2017 for W. Europe\n",
    "\n",
    "You will probably already have this dataset, but running the code below will make sure that you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the MODIS LAI dataset for 2016/2017 for W. Europe\n",
    "from geog0111.geog_data import procure_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "files = list(Path('data').glob('MCD15A3H.A201[6-7]*h1[7-8]v0[3-4].006*hdf'))\n",
    "if len(files) < 732:\n",
    "    _ = procure_dataset(\"lai_files\",verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.A.3 Get the shapefile for country borders\n",
    "\n",
    "Again, you should already have this, but just to make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "force = False\n",
    "# zip file\n",
    "zipfile = 'TM_WORLD_BORDERS-0.3.zip'\n",
    "# URL\n",
    "tm_borders_url = f\"http://thematicmapping.org/downloads/{zipfile}\"\n",
    "# destibnation folder\n",
    "destination_folder = Path('data')\n",
    "\n",
    "# set up some filenames\n",
    "zip_file = destination_folder.joinpath(zipfile)\n",
    "shape_file = zip_file.with_name(zipfile.replace('zip', 'shp'))\n",
    "\n",
    "# download zip if need to\n",
    "if not Path(zip_file).exists():\n",
    "    r = requests.get(tm_borders_url)\n",
    "    with open(zip_file, 'wb') as fp:\n",
    "        fp.write(r.content)\n",
    "\n",
    "# extract shp from zip if need to\n",
    "if force or not Path(shape_file).exists():\n",
    "    shutil.unpack_archive(zip_file.as_posix(), extract_dir=destination_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.A.4 Read the LAI dataset for a given country and year\n",
    "\n",
    "Run the code below to read in the LAI dataset for a given year and country. This uses codes we have developed in previous sections, interfaced through `process_timeseries()`.\n",
    "\n",
    "In the code, we can save the dataset as an `npz` file, so that we can access it faster next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the LAI data for given country code\n",
    "from geog0111.process_timeseries import process_timeseries\n",
    "'''\n",
    "Note, the saved npz file can be quite large\n",
    "e.g. 8.1 G for France.\n",
    "\n",
    "You can override saving it by setting save = False\n",
    "but if it is saved, it will be faster to access\n",
    "data the next time you need it.\n",
    "\n",
    "If you have a slow network, you might set download=False\n",
    "'''\n",
    "country_code = 'UK'\n",
    "year = 2017\n",
    "save = True\n",
    "download = True\n",
    "\n",
    "tiles = []\n",
    "for h in [17, 18]:\n",
    "    for v in [3, 4]:\n",
    "        tiles.append(f\"h{h:02d}v{v:02d}\")\n",
    "        \n",
    "fname = f'lai_data_{year}_{country_code}.npz'\n",
    "ofile = Path('data')/fname\n",
    "done = False\n",
    "\n",
    "if ofile.exists():\n",
    "    done = True\n",
    "    \n",
    "#Â try to download it from server\n",
    "if download:\n",
    "    done = procure_dataset(fname,verbose=True)\n",
    "    \n",
    "if not done:\n",
    "    # else generate it\n",
    "    dates, lai_array, weights_array = process_timeseries(year,tiles,\\\n",
    "                                                     country_code=country_code)\n",
    "    lai = {'dates':dates, 'lai':lai_array, 'weights':weights_array}\n",
    "    if save:\n",
    "        np.savez(ofile,**lai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.A.5 register with ECMWF and install the API\n",
    "\n",
    "Follow the [ECMWF instructions](https://confluence.ecmwf.int/display/WEBAPI/Access+ECMWF+Public+Datasets)\n",
    "\n",
    "First, you should [register as a user with ECMWF](https://apps.ecmwf.int/auth/login).\n",
    "\n",
    "The first time:\n",
    "\n",
    "* register and follow the emailed instructions.\n",
    "\n",
    "* read and acknowledge the [conditions of access and related information](https://www.ecmwf.int/en/computing/access-computing-facilities/conditions-access-ecmwf-computing-services).\n",
    "\n",
    "* follow the instructions on [how to access datasets](https://confluence.ecmwf.int/display/WEBAPI/Access+ECMWF+Public+Datasets) to receive and set up [an ECMWF key](https://confluence.ecmwf.int/display/WEBAPI/Access+ECMWF+Public+Datasets#AccessECMWFPublicDatasets-key)\n",
    "\n",
    "Help is available [online](https://confluence.ecmwf.int/display/UDOC/User+Documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ecmwf api -- do this once only\n",
    "ECMWF = 'https://software.ecmwf.int/wiki/download/attachments/56664858/ecmwf-api-client-python.tgz'\n",
    "try:\n",
    "    from ecmwfapi import ECMWFDataServer\n",
    "except:\n",
    "    import os\n",
    "    if os.name == 'nt':\n",
    "        # on windows\n",
    "        !pip install $ECMWF\n",
    "    else:\n",
    "        # on Unix/Linux\n",
    "        !pip install --user $ECMWF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2.4 Get the 2t dataset from ECMWF for Europe\n",
    "\n",
    "Run the code below to request and download the daily 2m temperature dataset for 2016 and 2017 (0.25 degree resolution) from the ECMWF ERA interim data.\n",
    "\n",
    "If the file already exists locally, the request will be ignored.\n",
    "\n",
    "If you do need to run the request, it may take several hours, depending on the ECMWF queue at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europe_data_2016_2017.nc exists\n"
     ]
    }
   ],
   "source": [
    "from ecmwfapi import ECMWFDataServer\n",
    "from pathlib import Path\n",
    "from geog0111.geog_data import procure_dataset\n",
    "\n",
    "ecmwf_file = 'europe_data_2016_2017.nc'\n",
    "\n",
    "if not (Path('data')/ecmwf_file).exists():\n",
    "    # try to get it from UCL servers\n",
    "    done = procure_dataset(ofile,verbose=True)\n",
    "    if not done:\n",
    "        server = ECMWFDataServer()\n",
    "        print('requesting data ... may take some time')\n",
    "        server.retrieve({\n",
    "            \"class\": \"ei\",\n",
    "            \"dataset\": \"interim\",\n",
    "            \"date\": \"2016-01-01/to/2017-12-31\", # Time period\n",
    "            \"expver\": \"1\",\n",
    "            \"levtype\": \"sfc\",\n",
    "            \"param\": \"2t\",           # Parameters. Here we use 2m Temperature (2t)  See the ECMWF parameter database, at http://apps.ecmwf.int/codes/grib/param-db\n",
    "            \"stream\": \"oper\",\n",
    "            \"type\": \"an\",\n",
    "            \"time\": \"12\",\n",
    "            \"step\": \"0\",\n",
    "            \"area\": \"75/-20/10/60\",    # Subset or clip to an area, here to Europe. Specify as North/West/South/East in Geographic lat/long degrees. Southern latitudes and Western longitudes must be given as negative numbers.\n",
    "            \"grid\": \"0.25/0.25\",        # Regrid from the default grid to a regular lat/lon with specified resolution. The first number is east-west resolution (longitude) and the second is north-south (latitude).\n",
    "            \"format\": \"netcdf\",         # Convert the output file from the default GRIB format to NetCDF format. Requires \"grid\" to be set to a regular lat/lon grid.\n",
    "            \"target\": f\"data/{ecmwf_file}\",  # The output file name. Set this to whatever you like.\n",
    "        })\n",
    "else: print(f'{ecmwf_file} exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2.5 Generate dataset wkt and correct ECMWF file\n",
    "\n",
    "The coordinate system of the ECMWF is peculiar in that it has a non-standard Earth spheroid.\n",
    "\n",
    "According to [ECMWF](https://confluence.ecmwf.int/plugins/servlet/mobile?contentId=56658069#content/view/56658069), the \n",
    "Earth model assumed for GRIB data (and inherited for other data products) uses a sphere with radius 6367.47 km, as defined in the [WMO GRIB Edition 1 specifications, Table 7, GDS Octet 17](http://www.wmo.int/pages/prog/www/WMOCodes/Guides/GRIB/GRIB1-Contents.html).\n",
    "\n",
    "We will mostly be dealing with netcdf files, as above. But it is not straightforward to get this projection information from the netcdf file.\n",
    "\n",
    "Instead, we access an example grib format file and save it as `data/Pacific.wind.7days.grb`. We then generate a wkt (well known text) format file [`data/grb.wkt`](data/grb.wkt) and insert this into the file using `gdal.Translate()`.\n",
    "\n",
    "The code below is quite complicated, buit needed to fix file format problems. It also converts the integer data into physical units (temperature in K) using the `-unscale` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GEOGCS[\"Coordinate System imported from GRIB file\",DATUM[\"unknown\",SPHEROID[\"Sphere\",6371200,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433]]']\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "# download example grib file from\n",
    "url = \"http://gribs2.gmn-usa.com/cgi-bin/\" +\\\n",
    "        \"weather_fetch.pl?parameter=wind&days=7&region=Pacific&dataset=nww3\"\n",
    "ofile = 'data/Pacific.wind.7days.grb'\n",
    "overwrite = False\n",
    "\n",
    "# get the example grib datafile\n",
    "# see\n",
    "# https://gis.stackexchange.com/questions/\n",
    "# 289314/using-gdal-to-read-data-from-grib-file-in-python\n",
    "output_fname = Path(ofile)\n",
    "with requests.Session() as session:\n",
    "    r1 = session.request('get',url)\n",
    "    if r1.url:\n",
    "        r2 = session.get(r1.url)\n",
    "        data = r2.content\n",
    "        d = 0\n",
    "        if overwrite or (not output_fname.exists()):  \n",
    "            with open(output_fname, 'wb') as fp:\n",
    "                d = fp.write(data)\n",
    "\n",
    "dataset = gdal.Open(ofile)\n",
    "wkt = dataset.GetProjection()\n",
    "with open('data/grb.wkt', 'w') as fp:\n",
    "    # write wkt to file\n",
    "    d = fp.write(wkt)\n",
    "    \n",
    "# use this to fix the downloaded file\n",
    "# which is ecmwf_file\n",
    "ifile = f\"data/{ecmwf_file}\"\n",
    "\n",
    "# need to sort the metadata\n",
    "meta = gdal.Open(ifile).GetMetadata()\n",
    "# get time info\n",
    "timer = np.array([(datetime(1900,1,1) + timedelta(days=float(i)/24.)) \\\n",
    "for i in meta['NETCDF_DIM_time_VALUES'][1:-1].split(',')])\n",
    "\n",
    "# pull the years info from ifile\n",
    "# if the file is multiple years eg europe_data_2010_2011.nc\n",
    "# then split it into multiple files\n",
    "years = np.array(Path(ifile).stem.split('_'))[2:].astype(int)\n",
    "\n",
    "# filter data for required year\n",
    "\n",
    "for year in years:\n",
    "    ofile = f'data/europe_data_{year}.nc'\n",
    "    mask = np.logical_and(timer >= datetime(year,1,1),timer <= datetime(year+1,1,1))\n",
    "    timer2 = timer[mask]\n",
    "    bands = ' '.join([f'-b {i}' for i in (np.where(mask)[0]+1)])    \n",
    "    timer3 = '{'+','.join(np.array(meta['NETCDF_DIM_time_VALUES'][1:-1].split(','))[mask])+'}'\n",
    "    timer4 = '{'+str(mask.sum())+',4}'\n",
    "    options = f\"-of netcdf -unscale -ot Float32 {bands} -mo NETCDF_DIM_time_VALUES={timer3}\" + \\\n",
    "              f\" -mo NETCDF_DIM_time_DEF={timer4} -a_srs data/grb.wkt\"\n",
    "    gdal.Translate(ofile+'tmp',ifile,options=options)\n",
    "    Path(ofile+'tmp').replace(ofile)\n",
    "    print(ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROJCS[\"MODIS Sinusoidal\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.01745329251994328,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"false_easting\",0.0],PARAMETER[\"false_northing\",0.0],PARAMETER[\"central_meridian\",0.0],PARAMETER[\"semi_major\",6371007.181],PARAMETER[\"semi_minor\",6371007.181],UNIT[\"m\",1.0],AUTHORITY[\"SR-ORG\",\"6974\"]]']\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Get the SRS 6974 for MODIS in case we want to use it\n",
    "'''\n",
    "\n",
    "url = 'http://spatialreference.org/ref/sr-org/6974/ogcwkt/'\n",
    "ofile = 'data/modis_6974.wkt'\n",
    "overwrite = False\n",
    "\n",
    "# http://spatialreference.org/ref/sr-org/6974\n",
    "output_fname = Path(ofile)\n",
    "with requests.Session() as session:\n",
    "    r1 = session.request('get',url)\n",
    "    if r1.url:\n",
    "        r2 = session.get(r1.url)\n",
    "        data = r2.text\n",
    "        d = 0\n",
    "        if overwrite or (not output_fname.exists()):  \n",
    "            with open(output_fname, 'w') as fp:\n",
    "                d = fp.write(data)\n",
    "\n",
    "# test opening it\n",
    "wkt2 = open(ofile,'r').readlines()\n",
    "\n",
    "print(wkt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
